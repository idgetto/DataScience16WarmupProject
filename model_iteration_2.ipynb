{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this iteration of predicting survival rates for the kaggle competition, [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic), I will try out a few more machine learning models. While doing this, I hope to learn why one algorithm is more effective than other for this problem. I'll also try to explain the tradeoffs of picking one model over another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, I will be exploring the following three models:\n",
    "1. Random Forests\n",
    "2. Boosting\n",
    "3. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "predictors = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "def clean_data(data_frame, predictors):\n",
    "    # convert Sex to binary, (male = 0, female = 1, )\n",
    "    data_frame.loc[data_frame.Sex == 'male', 'Sex'] = 0\n",
    "    data_frame.loc[data_frame.Sex == 'female', 'Sex'] = 1\n",
    "    \n",
    "    # convert Embarked to S = 0, C = 1, Q = 2    \n",
    "    data_frame.loc[data_frame.Embarked == 'S', 'Embarked'] = 0\n",
    "    data_frame.loc[data_frame.Embarked == 'C', 'Embarked'] = 1\n",
    "    data_frame.loc[data_frame.Embarked == 'Q', 'Embarked'] = 2\n",
    "\n",
    "    # fill all NaN's with the median value for that feature\n",
    "    for predictor in predictors:\n",
    "        data_frame[predictor] = data_frame[predictor].fillna(data_frame[predictor].median())\n",
    "        \n",
    "clean_data(train, predictors)\n",
    "clean_data(test, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Random Forest** model is a learning method that can be used for classification as well as regression. In our case we'll use the classification functionality because we want to predict the survival of passengers aboard the titanic. \n",
    "\n",
    "So how does the **Random Forest** model actually classify our data? This model relies on another machine learning model called **Decision Trees** to perform classifications and regressions. Since we're using a bunch of decision *trees*, we end up with a random *forest*. Because **Random Forests** uses another model, we call **Random Forests** an *ensemble* learner. It works by using an ensemble, or collection, of other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees\n",
    "\n",
    "Let's talk about **Decision Trees**. As the underlying model for **Random Forests**, **Decision Trees** must also be able to perform classifications and regressions. Here's what a decision tree might look like: \n",
    "\n",
    "![Titanic Decision Tree Image](img/decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the top of the diagram, we begin with all the passengers. If a passenger's sex is female(Sex=1) then they are sorted towards the right side of the tree, and males(Sex=0) are sorted toward the left side. Males are then sorted based on their age. Men younger than 6.5 filter into the next left node and men older than 6.5 filter into the lower node. We continue sorting the passengers based on similar questions. Once passenger's make their way to the lowest tier of nodes, their class is decided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Trees** work like we just saw above. They ask a series of question and sort the passenger's into categories based on the answer to those questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest is an Ensemble of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is created by generating a number of decision trees. Each of these decision trees is created using a random subset of the input data. That's where the *random* in random forests comes from. The decision trees then predict a class for a given passenger. Some may predict *Survived* and some might predict *Died*, but what's important is the majority vote. If two trees think Jack survived and three predict Jack died, then we go with the conclusion that Jack sadly died."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Random Forests\n",
    "\n",
    "* Classification or Regression problems\n",
    "* Noisy inputs\n",
    "* Many features of unknown importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With scikit-learn, using a random forest learner is simple. There are some optoional parameters that can affect the performance of the classifier though. The ones I've found to be more important are **max_depth**, the maximum depth of any of the decision trees used, and **n_estimators**, the number of decision trees to use. It is probably worthwhile to adjust these parameters to get the best score you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.809203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=4)\n",
    "scores = cross_val_score(clf, train[predictors], train.Survived, cv=3)\n",
    "print \"Cross Validation Score: %f\" % scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kaggle Score](img/kaggle_random_forest.png)\n",
    "\n",
    "Kaggle Score: 0.78947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/c/titanic/details/getting-started-with-random-forests\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "* https://en.wikipedia.org/wiki/Random_forest\n",
    "* https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "\n",
    "♪ all together now... ♫ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
